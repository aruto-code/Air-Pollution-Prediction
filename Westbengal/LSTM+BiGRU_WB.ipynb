{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf239c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas_datareader as pdr\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.engine.sequential import Sequential\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import LSTM ,Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('A:\\OverallDataset\\WestBengal\\OverallwestBengal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa76f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Function to check if a column contains string values\n",
    "def contains_strings(column):\n",
    "    return any(isinstance(value, str) for value in column)\n",
    "\n",
    "# Iterate through the columns and check for string values\n",
    "for column in df.columns:\n",
    "    if contains_strings(df[column]):\n",
    "        print(f\"Column '{column}' contains string values.\")\n",
    "    else:\n",
    "        print(f\"Column '{column}' does not contain string values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "df['From Date'] = pd.to_datetime(df['From Date'], format=\"%d-%m-%Y %H:%M\")\n",
    "df['To Date'] = pd.to_datetime(df['To Date'], format=\"%d-%m-%Y %H:%M\")\n",
    "\n",
    "# Verify the data types of the columns\n",
    "print(df.dtypes)\n",
    "\n",
    "\n",
    "# Now 'From Date' and 'To Date' are datetime data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Check for missing values in 'PM2.5 (ug/m3)' and 'PM10 (ug/m3)' columns\n",
    "missing_pm25 = df['PM2.5 (ug/m3)'].isnull().sum()\n",
    "missing_pm10 = df['PM10 (ug/m3)'].isnull().sum()\n",
    "\n",
    "if missing_pm25 > 0:\n",
    "    print(f\"Number of missing values in 'PM2.5 (ug/m3)': {missing_pm25}\")\n",
    "\n",
    "if missing_pm10 > 0:\n",
    "    print(f\"Number of missing values in 'PM10 (ug/m3)': {missing_pm10}\")\n",
    "\n",
    "# Check for outliers in 'PM2.5 (ug/m3)' and 'PM10 (ug/m3)' columns\n",
    "z_scores_pm25 = np.abs((df['PM2.5 (ug/m3)'] - df['PM2.5 (ug/m3)'].mean()) / df['PM2.5 (ug/m3)'].std())\n",
    "z_scores_pm10 = np.abs((df['PM10 (ug/m3)'] - df['PM10 (ug/m3)'].mean()) / df['PM10 (ug/m3)'].std())\n",
    "\n",
    "outliers_pm25 = (z_scores_pm25 > 3)\n",
    "outliers_pm10 = (z_scores_pm10 > 3)\n",
    "\n",
    "if outliers_pm25.any():\n",
    "    print(f\"Outliers detected in 'PM2.5 (ug/m3)':\")\n",
    "    print(df[outliers_pm25])\n",
    "\n",
    "if outliers_pm10.any():\n",
    "    print(f\"Outliers detected in 'PM10 (ug/m3)':\")\n",
    "    print(df[outliers_pm10])\n",
    "\n",
    "# Handle missing values and outliers as needed\n",
    "# You can choose to remove or impute missing values, and handle outliers according to your data analysis requirements.\n",
    "\n",
    "# After handling missing values and outliers, you can proceed with AQI calculations as shown in previous responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301504c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in 'PM2.5 (ug/m3)' and 'PM10 (ug/m3)' columns\n",
    "df = df.dropna(subset=['PM2.5 (ug/m3)', 'PM10 (ug/m3)'])\n",
    "\n",
    "# Calculate z-scores for 'PM2.5 (ug/m3)' and 'PM10 (ug/m3)' columns\n",
    "z_scores_pm25 = np.abs((df['PM2.5 (ug/m3)'] - df['PM2.5 (ug/m3)'].mean()) / df['PM2.5 (ug/m3)'].std())\n",
    "z_scores_pm10 = np.abs((df['PM10 (ug/m3)'] - df['PM10 (ug/m3)'].mean()) / df['PM10 (ug/m3)'].std())\n",
    "\n",
    "# Define a threshold for outliers (e.g., 3 standard deviations)\n",
    "outlier_threshold = 3\n",
    "\n",
    "# Drop rows with outliers in 'PM2.5 (ug/m3)' and 'PM10 (ug/m3)' columns\n",
    "df = df[~(z_scores_pm25 > outlier_threshold)]\n",
    "df = df[~(z_scores_pm10 > outlier_threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d50b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['PM2.5 (ug/m3)'].dtype)\n",
    "print(df['PM10 (ug/m3)'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c3059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa07210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming the actual column names in your dataset\n",
    "pm25_column = 'PM2.5 (ug/m3)'\n",
    "pm10_column = 'PM10 (ug/m3)'\n",
    "\n",
    "# Constants for AQI calculation (Indian standard)\n",
    "pm25_breakpoints = [0, 30, 60, 90, 120, 250]\n",
    "pm25_aqi_values = [0, 50, 100, 200, 300, 400, 500]\n",
    "\n",
    "pm10_breakpoints = [0, 50, 100, 250, 350, 430]\n",
    "pm10_aqi_values = [0, 50, 100, 200, 300, 400, 500]\n",
    "\n",
    "# Calculate AQI for PM2.5\n",
    "def calculate_aqi_pm25(pm25):\n",
    "    for i in range(len(pm25_breakpoints) - 1):\n",
    "        if pm25_breakpoints[i] <= pm25 <= pm25_breakpoints[i + 1]:\n",
    "            aqi = ((pm25_aqi_values[i + 1] - pm25_aqi_values[i]) / (pm25_breakpoints[i + 1] - pm25_breakpoints[i])) * (pm25 - pm25_breakpoints[i]) + pm25_aqi_values[i]\n",
    "            return aqi\n",
    "    return pm25_aqi_values[-1]\n",
    "\n",
    "# Calculate AQI for PM10\n",
    "def calculate_aqi_pm10(pm10):\n",
    "    for i in range(len(pm10_breakpoints) - 1):\n",
    "        if pm10_breakpoints[i] <= pm10 <= pm10_breakpoints[i + 1]:\n",
    "            aqi = ((pm10_aqi_values[i + 1] - pm10_aqi_values[i]) / (pm10_breakpoints[i + 1] - pm10_breakpoints[i])) * (pm10 - pm10_breakpoints[i]) + pm10_aqi_values[i]\n",
    "            return aqi\n",
    "    return pm10_aqi_values[-1]\n",
    "\n",
    "# Calculate AQI for each row in the dataset\n",
    "def calculate_aqi(row):\n",
    "    aqi_pm25 = calculate_aqi_pm25(row[pm25_column])\n",
    "    aqi_pm10 = calculate_aqi_pm10(row[pm10_column])\n",
    "    return max(aqi_pm25, aqi_pm10)\n",
    "\n",
    "# Apply the calculate_aqi function to your dataset\n",
    "df['AQI'] = df.apply(calculate_aqi, axis=1)\n",
    "\n",
    "# Now, your dataset should have an 'AQI' column with the calculated Air Quality Index.\n",
    "\n",
    "# You can further save this dataset or use it for analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f78290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02bd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = np.nan_to_num(X_train)  # Replace NaN with 0\n",
    "#X_test = np.nan_to_num(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check for NaN values in the entire DataFrame\n",
    "nan_df = df.isna()\n",
    "\n",
    "# Check for NaN values in a specific column\n",
    "nan_in_column = df['AQI'].isna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ccd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling all the null values with mean.\n",
    "columns_to_fill = [\n",
    "    'PM2.5 (ug/m3)',\n",
    "    'PM10 (ug/m3)',\n",
    "    'NOx (ppb)',\n",
    "    'SO2 (ug/m3)',\n",
    "    'CO (mg/m3)',\n",
    "    'Ozone (ug/m3)',\n",
    "]\n",
    "\n",
    "# Fill null values in the specified columns with their respective means\n",
    "df[columns_to_fill] = df[columns_to_fill].fillna(df[columns_to_fill].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f975810",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac638dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for infinite values in the entire DataFrame\n",
    "is_infinite = np.isinf(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37168108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows with infinite values\n",
    "rows_with_infinity = df[is_infinite.any(axis=1)]\n",
    "\n",
    "# Identify columns with infinite values\n",
    "columns_with_infinity = df.columns[is_infinite.any()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6600cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows with infinity:\")\n",
    "print(rows_with_infinity)\n",
    "\n",
    "print(\"Columns with infinity:\")\n",
    "print(columns_with_infinity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ed65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# List of columns to check for infinity\n",
    "columns_to_check = ['PM2.5 (ug/m3)', 'PM10 (ug/m3)',  'NOx (ppb)',\n",
    "                     'SO2 (ug/m3)', 'CO (mg/m3)', 'Ozone (ug/m3)', 'AQI']\n",
    "\n",
    "# Loop through the specified columns and print rows with infinity values\n",
    "for column_name in columns_to_check:\n",
    "    # Print rows where the specific column contains positive infinity\n",
    "    rows_with_infinity = df[df[column_name] == np.inf]\n",
    "\n",
    "    print(\"Rows with positive infinity in column {}: \".format(column_name))\n",
    "    print(rows_with_infinity)\n",
    "\n",
    "    # Print rows where the specific column contains negative infinity\n",
    "    rows_with_neg_infinity = df[df[column_name] == -np.inf]\n",
    "\n",
    "    print(\"Rows with negative infinity in column {}: \".format(column_name))\n",
    "    print(rows_with_neg_infinity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0314cb6e-677a-4968-86b6-11439de05c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Convert 'From Date' and 'To Date' to timestamps\n",
    "df['From Date'] = pd.to_datetime(df['From Date'])\n",
    "df['To Date'] = pd.to_datetime(df['To Date'])\n",
    "\n",
    "# Extract relevant features from the timestamp\n",
    "df['Year'] = df['From Date'].dt.year\n",
    "df['Month'] = df['From Date'].dt.month\n",
    "# Add more features as needed (e.g., day, hour, minute)\n",
    "\n",
    "# Define your target variable and features\n",
    "y = df['AQI']  # Assuming 'AQI' is the column with AQI values\n",
    "X = df.drop(columns=['AQI', 'From Date', 'To Date'])  # Exclude the AQI and date columns\n",
    "\n",
    "# Normalize your features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split your dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a custom attention layer\n",
    "class AttentionLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W_q = self.add_weight(name=\"W_q\", shape=(input_shape[-1], input_shape[-1]), initializer=\"uniform\")\n",
    "        self.W_k = self.add_weight(name=\"W_k\", shape=(input_shape[-1], input_shape[-1]), initializer=\"uniform\")\n",
    "        self.b_q = self.add_weight(name=\"b_q\", shape=(input_shape[-1],), initializer=\"zeros\")\n",
    "        self.b_k = self.add_weight(name=\"b_k\", shape=(input_shape[-1],), initializer=\"zeros\")\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        q = tf.nn.tanh(tf.matmul(inputs, self.W_q) + self.b_q)\n",
    "        k = tf.nn.tanh(tf.matmul(inputs, self.W_k) + self.b_k)\n",
    "\n",
    "        attention = tf.reduce_sum(q * k, axis=-1, keepdims=True)\n",
    "        attention = tf.nn.softmax(attention, axis=1)\n",
    "        output = inputs * attention\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "# Reshape the data for LSTM and Bi-GRU input\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Define the LSTM+Bi-GRU model with attention mechanism\n",
    "model = tf.keras.Sequential([\n",
    "    layers.LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "    AttentionLayer(),\n",
    "    layers.Bidirectional(layers.GRU(units=64, return_sequences=True)),\n",
    "    AttentionLayer(),\n",
    "    layers.Bidirectional(layers.GRU(units=64)),\n",
    "    layers.Dense(1)  # Output layer for AQI prediction\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=13, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions on training and testing data\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics for training data\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate performance metrics for testing data\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Training Metrics:\")\n",
    "print(\"MAE: \", mae_train)\n",
    "print(\"RMSE: \", rmse_train)\n",
    "print(\"R2: \", r2_train)\n",
    "\n",
    "print(\"\\nTesting Metrics:\")\n",
    "print(\"MAE: \", mae_test)\n",
    "print(\"RMSE: \", rmse_test)\n",
    "print(\"R2: \", r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be175f34-43a1-4baf-be25-755366d43ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
